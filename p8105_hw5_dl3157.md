ds\_hw5
================
Ditian Li
2018年11月6日

``` r
list.files("./data/")
```

    ##  [1] "con_01.csv" "con_02.csv" "con_03.csv" "con_04.csv" "con_05.csv"
    ##  [6] "con_06.csv" "con_07.csv" "con_08.csv" "con_09.csv" "con_10.csv"
    ## [11] "exp_01.csv" "exp_02.csv" "exp_03.csv" "exp_04.csv" "exp_05.csv"
    ## [16] "exp_06.csv" "exp_07.csv" "exp_08.csv" "exp_09.csv" "exp_10.csv"

``` r
files <- list.files(path = "./data/", pattern = "*.csv")
```

``` r
get_data <- function(i) {
  read.csv(paste0("./data/", i))
}

mydata<- files %>% 
  map(get_data) %>%
  reduce(rbind) %>% 
  janitor::clean_names()

mydata$type <- c(rep("con",10), rep("exp",10))
mydata$id <- c(rep(1:10,2))
mydata$study_id = paste0(mydata$type, mydata$id)
mydata <- mydata %>%
  gather(key = week, value = data, week_1:week_8) %>%  
  mutate(week = gsub("_", "", week))
```

``` r
mydata %>% 
  group_by(study_id) 
```

    ## # A tibble: 160 x 5
    ## # Groups:   study_id [20]
    ##    type     id study_id week   data
    ##    <chr> <int> <chr>    <chr> <dbl>
    ##  1 con       1 con1     week1  0.2 
    ##  2 con       2 con2     week1  1.13
    ##  3 con       3 con3     week1  1.77
    ##  4 con       4 con4     week1  1.04
    ##  5 con       5 con5     week1  0.47
    ##  6 con       6 con6     week1  2.37
    ##  7 con       7 con7     week1  0.03
    ##  8 con       8 con8     week1 -0.08
    ##  9 con       9 con9     week1  0.08
    ## 10 con      10 con10    week1  2.14
    ## # ... with 150 more rows

``` r
mydata %>% 
  ggplot(aes(x = week, y = data)) + 
    geom_line(aes(colour = type, group = study_id, linetype = type)) +
    theme(legend.position = "left") +
    labs(
      title = "Spaghetti plot of observations on each subject over week",
      x = "Week",
      y = "Observations"
    )
```

![](p8105_hw5_dl3157_files/figure-markdown_github/p1%20plot-1.png)

comment: From the plot, we can conclude that the trend of experimental group is roughly increased, the trend of control group kept the same, and experimental group has larger observations than control group overall.

``` r
homicide <- 
  read_csv("./data1/homicide-data.csv") %>% 
  janitor::clean_names()
```

    ## Parsed with column specification:
    ## cols(
    ##   uid = col_character(),
    ##   reported_date = col_integer(),
    ##   victim_last = col_character(),
    ##   victim_first = col_character(),
    ##   victim_race = col_character(),
    ##   victim_age = col_character(),
    ##   victim_sex = col_character(),
    ##   city = col_character(),
    ##   state = col_character(),
    ##   lat = col_double(),
    ##   lon = col_double(),
    ##   disposition = col_character()
    ## )

``` r
homicide 
```

    ## # A tibble: 52,179 x 12
    ##    uid       reported_date victim_last victim_first victim_race victim_age
    ##    <chr>             <int> <chr>       <chr>        <chr>       <chr>     
    ##  1 Alb-0000~      20100504 GARCIA      JUAN         Hispanic    78        
    ##  2 Alb-0000~      20100216 MONTOYA     CAMERON      Hispanic    17        
    ##  3 Alb-0000~      20100601 SATTERFIELD VIVIANA      White       15        
    ##  4 Alb-0000~      20100101 MENDIOLA    CARLOS       Hispanic    32        
    ##  5 Alb-0000~      20100102 MULA        VIVIAN       White       72        
    ##  6 Alb-0000~      20100126 BOOK        GERALDINE    White       91        
    ##  7 Alb-0000~      20100127 MALDONADO   DAVID        Hispanic    52        
    ##  8 Alb-0000~      20100127 MALDONADO   CONNIE       Hispanic    52        
    ##  9 Alb-0000~      20100130 MARTIN-LEY~ GUSTAVO      White       56        
    ## 10 Alb-0000~      20100210 HERRERA     ISRAEL       Hispanic    43        
    ## # ... with 52,169 more rows, and 6 more variables: victim_sex <chr>,
    ## #   city <chr>, state <chr>, lat <dbl>, lon <dbl>, disposition <chr>

This dataset contains 52179 obeservations, including variables as following:uid, reported date, victim first&last name, race, age, sex, city, state, latitude, longtitude and disposition.

``` r
homicide1<-homicide %>% 
  mutate(city_state = str_c(city, state, sep = ",")) %>% 
  select(city_state, everything())


homicide_s <- homicide1 %>% 
  group_by(city_state) %>% 
  mutate(total_n = n()) %>%
  filter(disposition %in% c("Closed without arrest","Open/No arrest"))   %>% 
  mutate(unsolved = n()) %>% 
  group_by(city_state, total_n, unsolved) %>% 
  summarize()

homicide_s
```

    ## # A tibble: 50 x 3
    ## # Groups:   city_state, total_n [?]
    ##    city_state     total_n unsolved
    ##    <chr>            <int>    <int>
    ##  1 Albuquerque,NM     378      146
    ##  2 Atlanta,GA         973      373
    ##  3 Baltimore,MD      2827     1825
    ##  4 Baton Rouge,LA     424      196
    ##  5 Birmingham,AL      800      347
    ##  6 Boston,MA          614      310
    ##  7 Buffalo,NY         521      319
    ##  8 Charlotte,NC       687      206
    ##  9 Chicago,IL        5535     4073
    ## 10 Cincinnati,OH      694      309
    ## # ... with 40 more rows

We Create a city\_state variable summarize within cities, and we obtained the total number of homicides and the number of unsolved homicides in 50 cities.

``` r
BT<-homicide_s %>% 
  filter(city_state == "Baltimore,MD") 
  
BT<-BT %>% 
  ungroup() %>% 
  mutate(total_n = as.numeric(total_n),
         unsolved = as.numeric(unsolved)) %>% 
  select(unsolved,total_n) 

BT_prop<-prop.test(BT$unsolved,BT$total_n)

BT_prop %>% 
  broom::tidy() %>% 
  select(estimate, conf.low, conf.high)
```

    ## # A tibble: 1 x 3
    ##   estimate conf.low conf.high
    ##      <dbl>    <dbl>     <dbl>
    ## 1    0.646    0.628     0.663

``` r
save(BT_prop,file = "BT_prop.RData")
```

For Baltimore, we used the prop.test function to estimate the proportion of homicides that are unsolved; the estimate is 0.646 with 95%CI(0.628,0.663).

``` r
city_prop_test = function(x){
  
  city_homicides = 
    homicide_s %>% 
    filter(city_state == x)
  
  prop.test(city_homicides$unsolved, city_homicides$total_n) %>% 
    broom::tidy() %>% 
    select(estimate, conf.low, conf.high)
}

city_prop = 
  tibble(city_state = homicide_s$city_state) %>% 
  mutate(map(.x = homicide_s$city_state, ~city_prop_test(.x))) %>% 
  unnest

city_prop
```

    ## # A tibble: 50 x 4
    ##    city_state     estimate conf.low conf.high
    ##    <chr>             <dbl>    <dbl>     <dbl>
    ##  1 Albuquerque,NM    0.386    0.337     0.438
    ##  2 Atlanta,GA        0.383    0.353     0.415
    ##  3 Baltimore,MD      0.646    0.628     0.663
    ##  4 Baton Rouge,LA    0.462    0.414     0.511
    ##  5 Birmingham,AL     0.434    0.399     0.469
    ##  6 Boston,MA         0.505    0.465     0.545
    ##  7 Buffalo,NY        0.612    0.569     0.654
    ##  8 Charlotte,NC      0.300    0.266     0.336
    ##  9 Chicago,IL        0.736    0.724     0.747
    ## 10 Cincinnati,OH     0.445    0.408     0.483
    ## # ... with 40 more rows

For all 50 cities, we used the prop.test function to estimate the proportion of homicides that are unsolved.

``` r
city_prop %>% 
  ggplot(aes(x = reorder(city_state,estimate), y = estimate, color = city_state)) + geom_point() +
  geom_errorbar(mapping = aes(ymin = conf.low, ymax = conf.high))+
theme_bw() +
  theme(legend.position = "left",
        axis.text.x = element_text(angle = 90, size = 7))+
 labs(
      title = "Estimated proportion of unsolved case across cities with error bars",
      x = "Cities",
      y = "Estimates"
    )
```

![](p8105_hw5_dl3157_files/figure-markdown_github/p2%20errorbar-1.png)

Comment:From the plot, top 3 cities have the largest proportion of unsolved homicides are Chicago, New Orleans,Baltimore, and Richmond,Charlotte and Memphis have the smallerst proprotion of unsolved homicides.
